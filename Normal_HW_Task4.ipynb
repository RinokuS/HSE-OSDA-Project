{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import fcalc\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - 2\n",
    "For solving task 1 and 2 we will define function for lazy FCA classification. \n",
    "\n",
    "This function will use compute intersect function for getting intersect between train row and row we want to classify. And function for computing extent based on the intersect. Also added function for computing intervals as argument with default value for future tasks 4 and 5. \n",
    "\n",
    "And as I working on Big Homework with FCALC Lazy Classifier, I decided to add it's classification to tasks 1-3 for fun (As interval functions there can not be modified for tasks 4 and 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_itersect(data_row, classification_row, interval_constructor=None):\n",
    "    intersection = []\n",
    "\n",
    "    if len(data_row) - len(classification_row) != 1 and len(data_row) != len(classification_row):\n",
    "        raise Exception\n",
    "\n",
    "    for i in range(len(classification_row)):\n",
    "        if type(classification_row[i]) is str:\n",
    "            if data_row[i] != classification_row[i]:\n",
    "                intersection.append('*')\n",
    "            else:\n",
    "                intersection.append(classification_row[i])\n",
    "        else:\n",
    "            if interval_constructor is None:\n",
    "                intersection.append((min(data_row[i], classification_row[i]), max(data_row[i], classification_row[i])))\n",
    "            else:\n",
    "                intersection.append(interval_constructor(data_row[i], classification_row[i]))\n",
    "\n",
    "    return np.array(intersection, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_extent(data, target, pattern):\n",
    "    extent = []\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return extent\n",
    "\n",
    "    if data.shape[1] - pattern.shape[0] != 1 and data.shape[1] != pattern.shape[0]:\n",
    "        raise Exception \n",
    "\n",
    "    for row_index in range(data.shape[0]):\n",
    "        row = data.iloc[row_index]\n",
    "        row_target = target.iloc[row_index]\n",
    "        is_fit = True\n",
    "        for i in range(len(pattern)):\n",
    "            if type(row[i]) is str:\n",
    "                if pattern[i] != '*' and row[i] != pattern[i]:\n",
    "                    is_fit = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[i] < pattern[i][0] or row[i] > pattern[i][1]:\n",
    "                    is_fit = False\n",
    "                    break\n",
    "        \n",
    "        if is_fit:\n",
    "            extent.append((row_index, row_target))\n",
    "\n",
    "    return extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificator(X_train, y_train, X_test, verbose=0, interval_constructor=None):\n",
    "    answers = []\n",
    "    for test_row in X_test.iloc:\n",
    "        is_classified = False\n",
    "        for train_row in X_train.iloc:\n",
    "            pattern = compute_itersect(train_row.to_list(), test_row.to_list(), interval_constructor=interval_constructor)\n",
    "            extent = compute_extent(X_train, y_train, pattern)\n",
    "            if verbose:\n",
    "                print(pattern)\n",
    "                print(extent)\n",
    "            if len(extent) != 0 and all(extent[0][1] == x[1] for x in extent):\n",
    "                answers.append(extent[0][1])\n",
    "                is_classified = True\n",
    "                break\n",
    "        if not is_classified:\n",
    "            answers.append('U')\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 8),\n",
       "    System   mount  price  con  snow  ice  dur Accegrade\n",
       " 0      SK       F    206  1.9   1.4  1.8  2.7         F\n",
       " 1     SRK  F or R    520  2.1   0.8  3.8  2.3         F\n",
       " 2      SK       F    160  1.7   1.9  1.6  3.7         F\n",
       " 3      SK       F    213  1.7   2.0  2.4  3.4         F\n",
       " 4     SMS  F or R    598  1.6   2.4  2.7  2.8         F\n",
       " 5      SK       F    109  2.0   1.9  2.4  3.7         F\n",
       " 6     SRK  F or R    325  2.0   2.1  3.2  2.8         F\n",
       " 7     SMS  F or R    498  1.5   3.3  3.5  2.0         T\n",
       " 8     SRK  F or R    396  2.8   2.1  3.1  2.5         T\n",
       " 9     SRK  F or R    325  2.2   2.2  4.6  3.2         T\n",
       " 10    SRK  F or R    389  2.0   2.2  3.3  4.3         T\n",
       " 11    SRK       F    298  2.5   2.3  3.3  2.8         T\n",
       " 12     SK       F    149  1.9   2.5  4.0  3.8         T\n",
       " 13    SMS  F or R    684  1.7   3.3  4.4  2.2         T\n",
       " 14     SK       F     99  2.8   2.2  2.5  4.0         T\n",
       " 15     SK       F    140  2.6   2.3  3.3  3.4         T\n",
       " 16     SK       F    215  2.3   3.8  4.8  2.3         T)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Wheel_Chains_Dataset.csv\", sep=';')\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 8),\n",
       "    System   mount  price  con  snow  ice  dur  Accegrade\n",
       " 0      SK       F    206  1.9   1.4  1.8  2.7      False\n",
       " 1     SRK  F or R    520  2.1   0.8  3.8  2.3      False\n",
       " 2      SK       F    160  1.7   1.9  1.6  3.7      False\n",
       " 3      SK       F    213  1.7   2.0  2.4  3.4      False\n",
       " 4     SMS  F or R    598  1.6   2.4  2.7  2.8      False\n",
       " 5      SK       F    109  2.0   1.9  2.4  3.7      False\n",
       " 6     SRK  F or R    325  2.0   2.1  3.2  2.8      False\n",
       " 7     SMS  F or R    498  1.5   3.3  3.5  2.0       True\n",
       " 8     SRK  F or R    396  2.8   2.1  3.1  2.5       True\n",
       " 9     SRK  F or R    325  2.2   2.2  4.6  3.2       True\n",
       " 10    SRK  F or R    389  2.0   2.2  3.3  4.3       True\n",
       " 11    SRK       F    298  2.5   2.3  3.3  2.8       True\n",
       " 12     SK       F    149  1.9   2.5  4.0  3.8       True\n",
       " 13    SMS  F or R    684  1.7   3.3  4.4  2.2       True\n",
       " 14     SK       F     99  2.8   2.2  2.5  4.0       True\n",
       " 15     SK       F    140  2.6   2.3  3.3  3.4       True\n",
       " 16     SK       F    215  2.3   3.8  4.8  2.3       True)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Accegrade\"] = data[\"Accegrade\"] == \"T\"\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[:-3].drop(columns=[\"Accegrade\"])\n",
    "y_train = data.iloc[:-3][\"Accegrade\"]\n",
    "X_test = data.iloc[-3:].drop(columns=[\"Accegrade\"])\n",
    "y_test = data.iloc[-3:][\"Accegrade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, 206) (1.9, 2.8) (1.4, 2.2) (1.8, 2.5) (2.7, 4.0)]\n",
      "[(0, False), (5, False)]\n",
      "['SK' 'F' (140, 206) (1.9, 2.6) (1.4, 2.3) (1.8, 3.3) (2.7, 3.4)]\n",
      "[(0, False)]\n",
      "['SK' 'F' (206, 215) (1.9, 2.3) (1.4, 3.8) (1.8, 4.8) (2.3, 2.7)]\n",
      "[(0, False)]\n",
      "[False, False, False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = classificator(X_train, y_train, X_test, verbose=1)\n",
    "print(prediction)\n",
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = fcalc.classifier.PatternBinaryClassifier(X_train.values, y_train.to_numpy(), categorical=[1, 2], method= \"ratio-support\")\n",
    "clf.predict(X_test.values)\n",
    "\n",
    "print(clf.predictions)\n",
    "actual_predictions = [i == 1 for i in clf.predictions]\n",
    "accuracy_score(actual_predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for results\n",
    "Here we have very poor accuracy. In my opinion, this is because we have only one object in most of our extents, so we have to change our algorithm a bit, such as taking the average prediction instead of just the first one, or changing the intervals calculating function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 8),\n",
       "    System   mount  price  con  snow  ice  dur Accegrade\n",
       " 0      SK       F    149  1.9   2.5  4.0  3.8         T\n",
       " 1     SRK  F or R    520  2.1   0.8  3.8  2.3         F\n",
       " 2     SRK  F or R    389  2.0   2.2  3.3  4.3         T\n",
       " 3      SK       F    213  1.7   2.0  2.4  3.4         F\n",
       " 4     SMS  F or R    598  1.6   2.4  2.7  2.8         F\n",
       " 5      SK       F    109  2.0   1.9  2.4  3.7         F\n",
       " 6     SRK  F or R    325  2.0   2.1  3.2  2.8         F\n",
       " 7     SMS  F or R    498  1.5   3.3  3.5  2.0         T\n",
       " 8     SRK  F or R    396  2.8   2.1  3.1  2.5         T\n",
       " 9      SK       F    160  1.7   1.9  1.6  3.7         F\n",
       " 10    SRK  F or R    389  2.0   2.2  3.3  4.3         T\n",
       " 11    SRK       F    298  2.5   2.3  3.3  2.8         T\n",
       " 12     SK       F    206  1.9   1.4  1.8  2.7         F\n",
       " 13    SMS  F or R    684  1.7   3.3  4.4  2.2         T\n",
       " 14     SK       F     99  2.8   2.2  2.5  4.0         T\n",
       " 15     SK       F    140  2.6   2.3  3.3  3.4         T\n",
       " 16     SK       F    215  2.3   3.8  4.8  2.3         T)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Wheel_Chains_Dataset_difforder.csv\", sep=';')\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 8),\n",
       "    System   mount  price  con  snow  ice  dur  Accegrade\n",
       " 0      SK       F    149  1.9   2.5  4.0  3.8       True\n",
       " 1     SRK  F or R    520  2.1   0.8  3.8  2.3      False\n",
       " 2     SRK  F or R    389  2.0   2.2  3.3  4.3       True\n",
       " 3      SK       F    213  1.7   2.0  2.4  3.4      False\n",
       " 4     SMS  F or R    598  1.6   2.4  2.7  2.8      False\n",
       " 5      SK       F    109  2.0   1.9  2.4  3.7      False\n",
       " 6     SRK  F or R    325  2.0   2.1  3.2  2.8      False\n",
       " 7     SMS  F or R    498  1.5   3.3  3.5  2.0       True\n",
       " 8     SRK  F or R    396  2.8   2.1  3.1  2.5       True\n",
       " 9      SK       F    160  1.7   1.9  1.6  3.7      False\n",
       " 10    SRK  F or R    389  2.0   2.2  3.3  4.3       True\n",
       " 11    SRK       F    298  2.5   2.3  3.3  2.8       True\n",
       " 12     SK       F    206  1.9   1.4  1.8  2.7      False\n",
       " 13    SMS  F or R    684  1.7   3.3  4.4  2.2       True\n",
       " 14     SK       F     99  2.8   2.2  2.5  4.0       True\n",
       " 15     SK       F    140  2.6   2.3  3.3  3.4       True\n",
       " 16     SK       F    215  2.3   3.8  4.8  2.3       True)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Accegrade\"] = data[\"Accegrade\"] == \"T\"\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[:-3].drop(columns=[\"Accegrade\"])\n",
    "y_train = data.iloc[:-3][\"Accegrade\"]\n",
    "X_test = data.iloc[-3:].drop(columns=[\"Accegrade\"])\n",
    "y_test = data.iloc[-3:][\"Accegrade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, 149) (1.9, 2.8) (2.2, 2.5) (2.5, 4.0) (3.8, 4.0)]\n",
      "[(0, True)]\n",
      "['SK' 'F' (140, 149) (1.9, 2.6) (2.3, 2.5) (3.3, 4.0) (3.4, 3.8)]\n",
      "[(0, True)]\n",
      "['SK' 'F' (149, 215) (1.9, 2.3) (2.5, 3.8) (4.0, 4.8) (2.3, 3.8)]\n",
      "[(0, True)]\n",
      "[True, True, True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = classificator(X_train, y_train, X_test, verbose=1)\n",
    "print(prediction)\n",
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = fcalc.classifier.PatternBinaryClassifier(X_train.values, y_train.to_numpy(), categorical=[1, 2], method= \"ratio-support\")\n",
    "clf.predict(X_test.values)\n",
    "\n",
    "print(clf.predictions)\n",
    "actual_predictions = [i == 1 for i in clf.predictions]\n",
    "accuracy_score(actual_predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for results\n",
    "As for here, if changing order of the dataset helps us improve the accuracy this much, it can't be assumed as correct metric. We should re-evaluate accuracy with cross-validation method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Here we use cross validation with 6 folds for computing appropriate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcalc_cross_validation(method, data, target, folds=5, verbose=0):\n",
    "    \"\"\"\n",
    "    Cross validation for counting Lazy FCA classifier avarage accuracy.\n",
    "    Arguments:\n",
    "        data (pandas.DataFrame) -- data frame with data for counting avarage accuracy\n",
    "        folds (int) -- number of folds for cross validation\n",
    "        verbose (int) -- value for controling logging, if 0 won't log anything otherwise print computation steps\n",
    "    Return: \n",
    "        avarage accuracy (float) -- return avarage accuracy for all folds\n",
    "        avarage f1 score (float) -- return avarage f1 score for all folds\n",
    "    \"\"\"\n",
    "    my_accuracies = np.array([])\n",
    "    fcalc_accuracies = np.array([])\n",
    "    fold_size = int(np.ceil(data.shape[0] / folds))\n",
    "\n",
    "    for i in range(0, data.shape[0], fold_size):\n",
    "        X_train = pd.concat([data.iloc[: i], data.iloc[i + fold_size:]])\n",
    "        y_train = pd.concat([target.iloc[: i], target.iloc[i + fold_size:]])\n",
    "\n",
    "        X_test = data.iloc[i : i + fold_size]\n",
    "        y_test = target.iloc[i : i + fold_size]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {i // fold_size + 1}\")\n",
    "\n",
    "        prediction = classificator(X_train, y_train, X_test, verbose=verbose)\n",
    "\n",
    "        clf = fcalc.classifier.PatternBinaryClassifier(X_train.values, y_train.to_numpy(), categorical=[1, 2], method=method)\n",
    "        clf.predict(X_test.values)\n",
    "        actual_predictions = [i == 1 for i in clf.predictions]\n",
    "\n",
    "        my_accuracy = accuracy_score(y_test, prediction)\n",
    "        fcalc_accuracy = accuracy_score(y_test, actual_predictions)\n",
    "\n",
    "        my_accuracies = np.append(my_accuracies, my_accuracy)\n",
    "        fcalc_accuracies = np.append(fcalc_accuracies, fcalc_accuracy)\n",
    "        if verbose:\n",
    "            print(\"My Accuracy for fold %d is %.2f \\n\"%(i // fold_size + 1, my_accuracy))\n",
    "            print(\"FCALC Accuracy for fold %d is %.2f \\n\"%(i // fold_size + 1, fcalc_accuracy))\n",
    "\n",
    "    return np.average(my_accuracies), np.average(fcalc_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My cross validation accuracy 65.00%\n",
      "FCALC cross validation accuracy 75.00%\n"
     ]
    }
   ],
   "source": [
    "my_accuracy, fcalc_accuracy = fcalc_cross_validation(method=\"ratio-support\", \n",
    "                                                    data=data.drop(columns=[\"Accegrade\"]), \n",
    "                                                    target=data[\"Accegrade\"])\n",
    "\n",
    "print(\"My cross validation accuracy %.2f\"%(my_accuracy * 100) + '%')\n",
    "print(\"FCALC cross validation accuracy %.2f\"%(fcalc_accuracy * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "Here we define new function for computing intervals and try it with object number 15. It looks like better method, but let's try cross validation for appropriate check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_inf_interval(a_1, a_2):\n",
    "    return (min(a_1, a_2), float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data.drop(columns=[\"Accegrade\"])\n",
    "target = data[\"Accegrade\"]\n",
    "\n",
    "X_train = pd.concat([raw_data.iloc[:14], raw_data.iloc[15:]])\n",
    "y_train = pd.concat([target.iloc[:14], target.iloc[15:]])\n",
    "\n",
    "X_test = raw_data.iloc[14:15]\n",
    "y_test = target.iloc[14:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, inf) (1.9, inf) (2.2, inf) (2.5, inf) (3.8, inf)]\n",
      "[(0, True)]\n",
      "[True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = classificator(X_train, y_train, X_test, verbose=1, interval_constructor=min_inf_interval)\n",
    "print(prediction)\n",
    "\n",
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "Another function for tring with object 15. It looks like worth method, but let's try cross validation for appropriate check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_inf_interval(a_1, a_2):\n",
    "    return (max(a_1, a_2), float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (149, inf) (2.8, inf) (2.5, inf) (4.0, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (520, inf) (2.8, inf) (2.2, inf) (3.8, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (389, inf) (2.8, inf) (2.2, inf) (3.3, inf) (4.3, inf)]\n",
      "[]\n",
      "['SK' 'F' (213, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (598, inf) (2.8, inf) (2.4, inf) (2.7, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (109, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (325, inf) (2.8, inf) (2.2, inf) (3.2, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (498, inf) (2.8, inf) (3.3, inf) (3.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (396, inf) (2.8, inf) (2.2, inf) (3.1, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (160, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (389, inf) (2.8, inf) (2.2, inf) (3.3, inf) (4.3, inf)]\n",
      "[]\n",
      "['*' 'F' (298, inf) (2.8, inf) (2.3, inf) (3.3, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (206, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (684, inf) (2.8, inf) (3.3, inf) (4.4, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (140, inf) (2.8, inf) (2.3, inf) (3.3, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (215, inf) (2.8, inf) (3.8, inf) (4.8, inf) (4.0, inf)]\n",
      "[]\n",
      "['U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rinok\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:226: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = classificator(X_train, y_train, X_test, verbose=1, interval_constructor=max_inf_interval)\n",
    "print(prediction)\n",
    "\n",
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for results\n",
    "\n",
    "We have tried two different methods for computing intervals. As we can see with our results, first method is more appropriate for our dataset\n",
    "\n",
    "Second one is too strict and we can't perform classification properly, giving objects an undefined tag."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1df68fc9fa01dac7be281f8dd0d32217a1f401dffd563477ddf5abfb5bb3b20b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
